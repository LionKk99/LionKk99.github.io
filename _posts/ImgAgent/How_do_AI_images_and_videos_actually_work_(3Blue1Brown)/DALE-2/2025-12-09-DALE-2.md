---
layout: post
title: "DALE-2"
date: 2025-12-09 01:51:35 +0800
categories: ['ImgAgent', 'How_do_AI_images_and_videos_actually_work_(3Blue1Brown)', 'DALE-2']
tags: ['ImgAgent', 'How_do_AI_images_and_videos_actually_work_(3Blue1Brown)', 'DALE-2']
image: "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V1.png"
math: true
toc: true
---

![V1.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V1.png" | absolute_url }})Diffusion通过Clip对文本的嵌入向量扩散出目标图像
![V2.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V2.png" | absolute_url }})通过引入额外的文本向量来去噪，通过文本向量的上下文，更好的去除噪声。（这个额外引导就像是之前的时间步t，t较小时就学习粗略的结构）
![V3.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V3.png" | absolute_url }})
但是仅仅引入文本引导是远远不够的！
![V4.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V4.png" | absolute_url }})
通过一个特殊的no class类来表示不加文本引导时的扩散
![V5.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V5.png" | absolute_url }})
将一般情况下（no class类）的引导向量减去，来更好的到达指定文本引导类的收敛点
![V6.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V6.png" | absolute_url }})对比两种向量引导的差距（黄色是同时收到两种引导，绿色是减去了一般引导），为什么不只用特殊类别的引导呢？（可能是这样可以像VAE一样采样到连续的目标区域，从而生成训练数据以外的图像）
![V7.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V7.png" | absolute_url }})
三种类别在引导下的收敛状态
![V8.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V8.png" | absolute_url }})更进一步，可以使用negative prompt来反方向进行引导
![V9.png]({{ "/images/ImgAgent/How_do_AI_images_and_videos_actually_work_(3Blue1Brown)/DALE-2/V9.png" | absolute_url }})
END!
